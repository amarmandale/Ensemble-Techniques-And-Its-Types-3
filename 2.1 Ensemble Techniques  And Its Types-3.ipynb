{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d0a721-42ec-418a-8923-925370852ff4",
   "metadata": {},
   "source": [
    "### Q1. What is Random Forest Regressor?\n",
    "The **Random Forest Regressor** is an ensemble learning method used for regression tasks. It consists of multiple decision trees trained on random subsets of the data. Each decision tree produces a prediction, and the **average of all treesâ€™ predictions** is taken as the final output. It is an extension of the Random Forest algorithm, which is used for both classification and regression.\n",
    "\n",
    "### Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "The **Random Forest Regressor** reduces overfitting by:\n",
    "- **Training multiple decision trees** on different random subsets of the dataset (bootstrapping). Each tree will be slightly different, leading to less overfitting to specific data points.\n",
    "- **Averaging predictions** across multiple trees smooths out the predictions, reducing variance. This prevents individual trees from making extreme predictions that lead to overfitting.\n",
    "\n",
    "### Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "In **Random Forest Regressor**, each decision tree produces a continuous numerical prediction for the target variable. The final prediction is obtained by:\n",
    "- **Averaging** the predictions from all the individual decision trees. This approach ensures that the overall prediction is more robust and reduces the effect of outlier predictions from individual trees.\n",
    "\n",
    "### Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "Some key **hyperparameters** of the Random Forest Regressor include:\n",
    "- **n_estimators**: The number of trees in the forest (e.g., 100, 200).\n",
    "- **max_depth**: The maximum depth of each decision tree (limits overfitting).\n",
    "- **min_samples_split**: The minimum number of samples required to split an internal node.\n",
    "- **min_samples_leaf**: The minimum number of samples required to be at a leaf node.\n",
    "- **max_features**: The number of features to consider when looking for the best split (e.g., 'sqrt', 'log2').\n",
    "- **bootstrap**: Whether bootstrap samples are used when building trees (usually set to `True`).\n",
    "\n",
    "### Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "- **Decision Tree Regressor**: A single tree that makes predictions based on recursive partitioning of the data. It is prone to **overfitting** if the tree grows too deep.\n",
    "- **Random Forest Regressor**: An ensemble of multiple decision trees, which improves generalization by averaging the predictions of many trees, thus **reducing overfitting**.\n",
    "\n",
    "### Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "**Advantages**:\n",
    "- **Reduces overfitting**: By combining the predictions of many trees, Random Forest creates more generalized models compared to individual decision trees.\n",
    "- **Handles large datasets** well: It can efficiently handle high-dimensional data with many features.\n",
    "- **Works well with missing values**: It can handle datasets with missing data and provide robust results.\n",
    "  \n",
    "**Disadvantages**:\n",
    "- **Slower prediction time**: Since it averages over many trees, it can be slower to make predictions compared to a single decision tree.\n",
    "- **Less interpretability**: Random Forests are harder to interpret compared to decision trees because of the ensemble nature.\n",
    "\n",
    "### Q7. What is the output of Random Forest Regressor?\n",
    "The **output of Random Forest Regressor** is a **continuous numerical value** that represents the predicted value for a given input. In the case of regression tasks, the output is the **average of the predictions** made by the individual decision trees in the forest.\n",
    "\n",
    "### Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "No, the **Random Forest Regressor** is specifically designed for **regression** tasks, where the output is a continuous value. However, the **Random Forest algorithm** has a classification counterpart known as the **Random Forest Classifier**, which is used for classification tasks. The key difference is that the classifier uses majority voting across decision trees for classification, while the regressor uses averaging for continuous outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c92e1ee-c0c3-4d1d-9677-d5162faa30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of the Random Forest Regressor: 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error of the Random Forest Regressor: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68160197-0d5c-498a-acc4-45725813c69f",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- The California Housing dataset is used, which is suitable for regression tasks.\n",
    "- The rest of the code remains the same for training and evaluating the Random Forest Regressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2738b-d411-498a-bf7a-91096f12a1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
